{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/k_/llg_23_134bchy4_dydf9flr0000gn/T//RtmpEIIGoe/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"reinforcelearn\")\n",
    "library(reinforcelearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Documentation:** https://cran.r-project.org/web/packages/reinforcelearn/reinforcelearn.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gridworld](https://www.researchgate.net/profile/Alexey_Melnikov2/publication/262526038/figure/fig2/AS:296823253159943@1447779586992/The-grid-world-task-The-goal-of-the-game-is-to-find-the-star-At-the-beginning-of-each.png)\n",
    "\n",
    "The grid-world task: The goal of the game is to find the “star”. At the beginning of each trial the agent is placed in the (1,3) cell, as shown. The shortest path to the goal is composed of 14 steps, one such optimal path is marked by a dashed line. (source: https://www.researchgate.net/figure/The-grid-world-task-The-goal-of-the-game-is-to-find-the-star-At-the-beginning-of-each_fig2_262526038)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " o - - - \n",
      " - - - - \n",
      " - - - - \n",
      " - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the reinforcement learning environment with makeEnvironment.\n",
    "#There are some predefined environment classes, e.g. MDPEnvironment,\n",
    "#which allows you to create a Markov Decision Process by passing on state transition \n",
    "#array and reward matrix, or GymEnvironment, where you can use toy problems from OpenAI Gym.\n",
    "env = makeEnvironment(\"gridworld\", shape = c(4, 4), goal.states = 15, initial.state = 0)\n",
    "env$visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With makeAgent you can set up a reinforcement learning agent to solve the environment,\n",
    "#i.e. to find the best action in each time step.\n",
    "#The first step is to set up the policy, which defines which action to choose. \n",
    "# Create qlearning agent with softmax policy and tabular value function.\n",
    "policy = makePolicy(\"softmax\")\n",
    "values = makeValueFunction(\"table\", n.states = env$n.states, n.actions = env$n.actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want the agent to be able to learn something. Value-based algorithms learn a value \n",
    "#function from interaction with the environment and adjust the policy according to the \n",
    "#value function. For example we could set up Q-Learning with a softmax policy.\n",
    "algorithm = makeAlgorithm(\"qlearning\")\n",
    "agent = makeAgent(policy, values, algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1 finished after 137 steps with a return of -137\n",
      "Episode 2 finished after 27 steps with a return of -27\n",
      "Episode 3 finished after 64 steps with a return of -64\n",
      "Episode 4 finished after 61 steps with a return of -61\n",
      "Episode 5 finished after 38 steps with a return of -38\n",
      "Episode 6 finished after 19 steps with a return of -19\n",
      "Episode 7 finished after 61 steps with a return of -61\n",
      "Episode 8 finished after 28 steps with a return of -28\n",
      "Episode 9 finished after 44 steps with a return of -44\n",
      "Episode 10 finished after 91 steps with a return of -91\n",
      "Episode 11 finished after 27 steps with a return of -27\n",
      "Episode 12 finished after 42 steps with a return of -42\n",
      "Episode 13 finished after 86 steps with a return of -86\n",
      "Episode 14 finished after 42 steps with a return of -42\n",
      "Episode 15 finished after 18 steps with a return of -18\n",
      "Episode 16 finished after 30 steps with a return of -30\n",
      "Episode 17 finished after 20 steps with a return of -20\n",
      "Episode 18 finished after 43 steps with a return of -43\n",
      "Episode 19 finished after 40 steps with a return of -40\n",
      "Episode 20 finished after 14 steps with a return of -14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$returns</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>-137</li>\n",
       "\t<li>-27</li>\n",
       "\t<li>-64</li>\n",
       "\t<li>-61</li>\n",
       "\t<li>-38</li>\n",
       "\t<li>-19</li>\n",
       "\t<li>-61</li>\n",
       "\t<li>-28</li>\n",
       "\t<li>-44</li>\n",
       "\t<li>-91</li>\n",
       "\t<li>-27</li>\n",
       "\t<li>-42</li>\n",
       "\t<li>-86</li>\n",
       "\t<li>-42</li>\n",
       "\t<li>-18</li>\n",
       "\t<li>-30</li>\n",
       "\t<li>-20</li>\n",
       "\t<li>-43</li>\n",
       "\t<li>-40</li>\n",
       "\t<li>-14</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$steps</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>137</li>\n",
       "\t<li>27</li>\n",
       "\t<li>64</li>\n",
       "\t<li>61</li>\n",
       "\t<li>38</li>\n",
       "\t<li>19</li>\n",
       "\t<li>61</li>\n",
       "\t<li>28</li>\n",
       "\t<li>44</li>\n",
       "\t<li>91</li>\n",
       "\t<li>27</li>\n",
       "\t<li>42</li>\n",
       "\t<li>86</li>\n",
       "\t<li>42</li>\n",
       "\t<li>18</li>\n",
       "\t<li>30</li>\n",
       "\t<li>20</li>\n",
       "\t<li>43</li>\n",
       "\t<li>40</li>\n",
       "\t<li>14</li>\n",
       "</ol>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$returns] \\begin{enumerate*}\n",
       "\\item -137\n",
       "\\item -27\n",
       "\\item -64\n",
       "\\item -61\n",
       "\\item -38\n",
       "\\item -19\n",
       "\\item -61\n",
       "\\item -28\n",
       "\\item -44\n",
       "\\item -91\n",
       "\\item -27\n",
       "\\item -42\n",
       "\\item -86\n",
       "\\item -42\n",
       "\\item -18\n",
       "\\item -30\n",
       "\\item -20\n",
       "\\item -43\n",
       "\\item -40\n",
       "\\item -14\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$steps] \\begin{enumerate*}\n",
       "\\item 137\n",
       "\\item 27\n",
       "\\item 64\n",
       "\\item 61\n",
       "\\item 38\n",
       "\\item 19\n",
       "\\item 61\n",
       "\\item 28\n",
       "\\item 44\n",
       "\\item 91\n",
       "\\item 27\n",
       "\\item 42\n",
       "\\item 86\n",
       "\\item 42\n",
       "\\item 18\n",
       "\\item 30\n",
       "\\item 20\n",
       "\\item 43\n",
       "\\item 40\n",
       "\\item 14\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$returns\n",
       ":   1. -137\n",
       "2. -27\n",
       "3. -64\n",
       "4. -61\n",
       "5. -38\n",
       "6. -19\n",
       "7. -61\n",
       "8. -28\n",
       "9. -44\n",
       "10. -91\n",
       "11. -27\n",
       "12. -42\n",
       "13. -86\n",
       "14. -42\n",
       "15. -18\n",
       "16. -30\n",
       "17. -20\n",
       "18. -43\n",
       "19. -40\n",
       "20. -14\n",
       "\n",
       "\n",
       "\n",
       "$steps\n",
       ":   1. 137\n",
       "2. 27\n",
       "3. 64\n",
       "4. 61\n",
       "5. 38\n",
       "6. 19\n",
       "7. 61\n",
       "8. 28\n",
       "9. 44\n",
       "10. 91\n",
       "11. 27\n",
       "12. 42\n",
       "13. 86\n",
       "14. 42\n",
       "15. 18\n",
       "16. 30\n",
       "17. 20\n",
       "18. 43\n",
       "19. 40\n",
       "20. 14\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$returns\n",
       " [1] -137  -27  -64  -61  -38  -19  -61  -28  -44  -91  -27  -42  -86  -42  -18\n",
       "[16]  -30  -20  -43  -40  -14\n",
       "\n",
       "$steps\n",
       " [1] 137  27  64  61  38  19  61  28  44  91  27  42  86  42  18  30  20  43  40\n",
       "[20]  14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run interaction for 20 steps.\n",
    "interact(env, agent, n.episodes = 20L)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir33"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
