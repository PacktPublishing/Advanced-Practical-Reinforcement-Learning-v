{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "#create keras model\n",
    "#create action function\n",
    "#create memory function\n",
    "#create replay function\n",
    "#ceate train model function\n",
    "class DQN:\n",
    "    def __init__(self, env):\n",
    "        self.env     = env\n",
    "        self.memory  = deque(maxlen=2000)\n",
    "        \n",
    "        self.gamma = 0.85\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.005\n",
    "        self.tau = .125\n",
    "\n",
    "        self.model        = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        state_shape  = self.env.observation_space.shape\n",
    "        model.add(Dense(24, input_dim=state_shape[0], activation=\"relu\"))\n",
    "        model.add(Dense(48, activation=\"relu\"))\n",
    "        model.add(Dense(24, activation=\"relu\"))\n",
    "        model.add(Dense(self.env.action_space.n))\n",
    "        model.compile(loss=\"mean_squared_error\",\n",
    "            optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.append([state, action, reward, new_state, done])\n",
    "\n",
    "    def replay(self):\n",
    "        batch_size = 32\n",
    "        if len(self.memory) < batch_size: \n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        for sample in samples:\n",
    "            state, action, reward, new_state, done = sample\n",
    "            target = self.target_model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                Q_future = max(self.target_model.predict(new_state)[0])\n",
    "                target[0][action] = reward + Q_future * self.gamma\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "    def target_train(self):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    def save_model(self, fn):\n",
    "        self.model.save(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to complete in trial 0\n",
      "Failed to complete in trial 1\n",
      "Failed to complete in trial 2\n",
      "Failed to complete in trial 3\n",
      "Failed to complete in trial 4\n",
      "Failed to complete in trial 5\n",
      "Failed to complete in trial 6\n",
      "Failed to complete in trial 7\n",
      "Failed to complete in trial 8\n",
      "Failed to complete in trial 9\n",
      "Failed to complete in trial 10\n",
      "Failed to complete in trial 11\n",
      "Failed to complete in trial 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (555.721760). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to complete in trial 13\n",
      "Failed to complete in trial 14\n",
      "Failed to complete in trial 15\n",
      "Failed to complete in trial 16\n",
      "Failed to complete in trial 17\n",
      "Failed to complete in trial 18\n",
      "Failed to complete in trial 19\n",
      "Failed to complete in trial 20\n",
      "Failed to complete in trial 21\n",
      "Failed to complete in trial 22\n",
      "Failed to complete in trial 23\n",
      "Failed to complete in trial 24\n",
      "Failed to complete in trial 25\n",
      "Failed to complete in trial 26\n",
      "Failed to complete in trial 27\n",
      "Failed to complete in trial 28\n",
      "Failed to complete in trial 29\n",
      "Failed to complete in trial 30\n",
      "Failed to complete in trial 31\n",
      "Failed to complete in trial 32\n",
      "Failed to complete in trial 33\n",
      "Failed to complete in trial 34\n",
      "Failed to complete in trial 35\n",
      "Failed to complete in trial 36\n",
      "Failed to complete in trial 37\n",
      "Failed to complete in trial 38\n",
      "Failed to complete in trial 39\n",
      "Failed to complete in trial 40\n",
      "Failed to complete in trial 41\n",
      "Failed to complete in trial 42\n",
      "Failed to complete in trial 43\n",
      "Failed to complete in trial 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.111539). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to complete in trial 45\n",
      "Failed to complete in trial 46\n",
      "Failed to complete in trial 47\n",
      "Completed in 48 trials\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    env     = gym.make(\"MountainCar-v0\")\n",
    "    gamma   = 0.9\n",
    "    epsilon = .95\n",
    "\n",
    "    trials  = 1000\n",
    "    trial_len = 500\n",
    "\n",
    "    # updateTargetNetwork = 1000\n",
    "    dqn_agent = DQN(env=env)\n",
    "    steps = []\n",
    "    for trial in range(trials):\n",
    "        cur_state = env.reset().reshape(1,2)\n",
    "        for step in range(trial_len):\n",
    "            action = dqn_agent.act(cur_state)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            # reward = reward if not done else -20\n",
    "            new_state = new_state.reshape(1,2)\n",
    "            dqn_agent.remember(cur_state, action, reward, new_state, done)\n",
    "            \n",
    "            dqn_agent.replay()       # internally iterates default (prediction) model\n",
    "            dqn_agent.target_train() # iterates target model\n",
    "\n",
    "            cur_state = new_state\n",
    "            if done:\n",
    "                break\n",
    "        if step >= 199:\n",
    "            env.render()\n",
    "            print(\"Failed to complete in trial {}\".format(trial))\n",
    "            if step % 10 == 0:\n",
    "                dqn_agent.save_model(\"trial-{}.model\".format(trial))\n",
    "        else:\n",
    "            print(\"Completed in {} trials\".format(trial))\n",
    "            dqn_agent.save_model(\"success.model\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
