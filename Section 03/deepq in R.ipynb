{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"reinforcelearn\")\n",
    "library(reinforcelearn)\n",
    "#install.packages(\"keras\")\n",
    "library(keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Documentation:** https://cran.r-project.org/web/packages/reinforcelearn/reinforcelearn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = makeEnvironment(\"gym\", gym.name = \"MountainCar-v0\")\n",
    "# Create qlearning agent with softmax policy and tabular value function.\n",
    "policy = makePolicy(\"softmax\")\n",
    "values = makeValueFunction(\"table\", n.states = env$n.states, n.actions = env$n.actions)\n",
    "algorithm = makeAlgorithm(\"qlearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_model_sequential()\n",
    "model %>% layer_dense(20, input_shape = 10, activation = \"relu\")\n",
    "model %>% layer_dense(4, activation = \"relu\")\n",
    "keras::compile(model, loss = \"mae\", optimizer = keras::optimizer_sgd(lr = 0.4))\n",
    "val = makeValueFunction(\"neural.network\", model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = makeAgent(policy, val, algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-0.432580498553659</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.432580498553659\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.432580498553659\n",
       "2. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.4325805  0.0000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take random actions for 200 steps.\n",
    "env$reset()\n",
    "for (i in 1:200) {\n",
    "  action = sample(0:2, 1)\n",
    "  env$step(action)\n",
    "  env$visualize()\n",
    "}\n",
    "env$close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir33"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
